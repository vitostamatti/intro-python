{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a4_7UAWVsBRT"
      },
      "source": [
        "# NLP - Hugging Face\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/vitostamatti/intro-python/blob/main/notebooks/06-nlp.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W2afgA0YuQTD"
      },
      "source": [
        "The Transformer architecture was introduced in June 2017. The focus of the original research was on translation tasks. This was followed by the introduction of several influential models.\n",
        "\n",
        "- June 2018: GPT, the first pretrained Transformer model.\n",
        "- October 2018: BERT, another large pretrained model, this one designed to produce better summaries of sentences.\n",
        "- February 2019: GPT-2, an improved (and bigger) version of GPT.\n",
        "- October 2019: DistilBERT, a distilled version of BERT that is 60% faster, 40% lighter in memory, and still retains 97% of BERT's performance\n",
        "- October 2019: BART and T5, two large pretrained models using the same architecture as the original Transformer.\n",
        "- May 2020, GPT-3, an even bigger version of GPT-2.\n",
        "\n",
        "![image](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_chrono.svg)\n",
        "\n",
        "This list is far from comprehensive, and is just meant to highlight a few of the different kinds of Transformer models. Broadly, they can be grouped into three categories:\n",
        "\n",
        "- GPT-like (also called auto-regressive Transformer models)\n",
        "- BERT-like (also called auto-encoding Transformer models)\n",
        "- BART/T5-like (also called sequence-to-sequence Transformer models)\n",
        "\n",
        "Apart from a few outliers (like DistilBERT), the general strategy to achieve better performance is by increasing the models' sizes as well as the amount of data they are pretrained on.\n",
        "\n",
        "![image](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/model_parameters.png)\n",
        "\n",
        "## Transfer Learning\n",
        "\n",
        "Pretraining is the act of training a model from scratch: the weights are randomly initialized, and the training starts without any prior knowledge.\n",
        "This pretraining is usually done on very large amounts of data. Therefore, it requires a very large corpus of data, and training can take up to several weeks.\n",
        "\n",
        "![image](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/pretraining.svg)\n",
        "\n",
        "Fine-tuning, on the other hand, is the training done after a model has been pretrained. To perform fine-tuning, you first acquire a pretrained language model, then perform additional training with a dataset specific to your task.\n",
        "\n",
        "![image](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/finetuning.svg)\n",
        "\n",
        "Fine-tuning a model therefore has lower time, data, financial, and environmental costs. It is also quicker and easier to iterate over different fine-tuning schemes, as the training is less constraining than a full pretraining.\n",
        "\n",
        "This process will also achieve better results than training from scratch (unless you have lots of data), which is why you should always try to leverage a pretrained model — one as close as possible to the task you have at hand — and fine-tune it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QSt167IsBRX"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO5WyKVSsBRX",
        "outputId": "204301eb-4948-4263-b1c1-a5ac998cf5cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598047137260437}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWOElUtZsBRY",
        "outputId": "db285880-6327-4e92-e0c1-24569266c696"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzTdAD3QsBRZ",
        "outputId": "0b1b8d14-cd5f-4052-cb43-98730c99a2b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sequence': 'This is a course about the Transformers library',\n",
              " 'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQT_jobxsBRZ",
        "outputId": "9dbb1a88-8ab4-4906-e234-253833fdd821"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to understand and use '\n",
              "                    'data flow and data interchange when handling user data. We '\n",
              "                    'will be working with one or more of the most commonly used '\n",
              "                    'data flows — data flows of various types, as seen by the '\n",
              "                    'HTTP'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this course, we will teach you how to\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRMvdUaBsBRZ",
        "outputId": "427331c0-a118-4d97-9234-e24dba29b071"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to manipulate the world and '\n",
              "                    'move your mental and physical capabilities to your advantage.'},\n",
              " {'generated_text': 'In this course, we will teach you how to become an expert and '\n",
              "                    'practice realtime, and with a hands on experience on both real '\n",
              "                    'time and real'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bgmkug5ysBRa",
        "outputId": "ae3272b7-c150-4be6-efc0-711085ad42f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'sequence': 'This course will teach you all about mathematical models.',\n",
              "  'score': 0.19619831442832947,\n",
              "  'token': 30412,\n",
              "  'token_str': ' mathematical'},\n",
              " {'sequence': 'This course will teach you all about computational models.',\n",
              "  'score': 0.04052725434303284,\n",
              "  'token': 38163,\n",
              "  'token_str': ' computational'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaseHz9_sBRa",
        "outputId": "7d3be649-2cce-4469-ee37-da5cd4f1e474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, \n",
              " {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, \n",
              " {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}\n",
              "]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdEZd1rXsBRb",
        "outputId": "265a51f5-9959-41db-b67c-aedc1c9adcd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKlbCmx8sBRb",
        "outputId": "6521f432-daec-4dab-8fa1-7613b55ca831"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': ' America has changed dramatically during recent years . The '\n",
              "                  'number of engineering graduates in the U.S. has declined in '\n",
              "                  'traditional engineering disciplines such as mechanical, civil '\n",
              "                  ', electrical, chemical, and aeronautical engineering . Rapidly '\n",
              "                  'developing economies such as China and India, as well as other '\n",
              "                  'industrial countries in Europe and Asia, continue to encourage '\n",
              "                  'and advance engineering .'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of \n",
        "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
        "    the premier American universities engineering curricula now concentrate on \n",
        "    and encourage largely the study of engineering science. As a result, there \n",
        "    are declining offerings in engineering subjects dealing with infrastructure, \n",
        "    the environment, and related issues, and greater concentration on high \n",
        "    technology subjects, largely supporting increasingly complex scientific \n",
        "    developments. While the latter is important, it should not be at the expense \n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other \n",
        "    industrial countries in Europe and Asia, continue to encourage and advance \n",
        "    the teaching of engineering. Both China and India, respectively, graduate \n",
        "    six and eight times as many traditional engineers as does the United States. \n",
        "    Other industrial countries at minimum maintain their output, while America \n",
        "    suffers an increasingly serious decline in the number of engineering graduates \n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3iz8ZePsBRb",
        "outputId": "4ff01e48-4162-44b2-ed08-0053fdfe9736"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'translation_text': 'This course is produced by Hugging Face.'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"Ce cours est produit par Hugging Face.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
